{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weights checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _RegNet_Y_400MF_torch_weights_mapping(old_key, new_key):\n",
    "    W_KEY = [\"conv1/weight\", \"conv2/weight\", \"conv3/weight\", \"downsample/0/weight\"]\n",
    "    new_mapping = new_key\n",
    "    if builtins.any([kc in old_key for kc in W_KEY]):\n",
    "        new_mapping = {\"key_chain\": new_key, \"pattern\": \"b c h w -> h w c b\"}\n",
    "    return new_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ivy, torch\n",
    "\n",
    "\n",
    "def _prune_keys(raw, ref, raw_keys_to_prune=[], ref_keys_to_prune=[]):\n",
    "    pruned_ref = {}\n",
    "    if raw_keys_to_prune:\n",
    "        raw = raw.cont_prune_keys(raw_keys_to_prune)\n",
    "    if ref_keys_to_prune:\n",
    "        pruned_ref = ref.cont_at_keys(ref_keys_to_prune)\n",
    "        ref = ref.cont_prune_keys(ref_keys_to_prune)\n",
    "    return raw, ref, pruned_ref\n",
    "\n",
    "\n",
    "def _map_weights(raw, ref, custom_mapping=None):\n",
    "    mapping = {}\n",
    "    for old_key, new_key in zip(\n",
    "        raw.cont_sort_by_key().cont_to_iterator_keys(),\n",
    "        ref.cont_sort_by_key().cont_to_iterator_keys(),\n",
    "    ):\n",
    "        new_mapping = new_key\n",
    "        if custom_mapping is not None:\n",
    "            new_mapping = custom_mapping(old_key, new_key)\n",
    "        mapping[old_key] = new_mapping\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def load_torch_weights(\n",
    "    url,\n",
    "    ref_model,\n",
    "    raw_keys_to_prune=[],\n",
    "    ref_keys_to_prune=[],\n",
    "    custom_mapping=None,\n",
    "    map_location=torch.device(\"cpu\"),\n",
    "):\n",
    "    ivy_torch = ivy.with_backend(\"torch\")\n",
    "    weights = torch.hub.load_state_dict_from_url(url, map_location=map_location)\n",
    "\n",
    "    from pprint import pprint as pp\n",
    "\n",
    "    pp(weights)\n",
    "\n",
    "    weights_raw = ivy.Container(\n",
    "        ivy_torch.to_numpy(ivy_torch.Container(weights)).cont_to_dict()\n",
    "    )\n",
    "    weights_raw, weights_ref, pruned_ref = _prune_keys(\n",
    "        weights_raw, ref_model.v, raw_keys_to_prune, ref_keys_to_prune\n",
    "    )\n",
    "    mapping = _map_weights(weights_raw, weights_ref, custom_mapping=custom_mapping)\n",
    "    w_clean = weights_raw.cont_restructure(mapping, keep_orig=False)\n",
    "    if ref_keys_to_prune:\n",
    "        w_clean = ivy.Container.cont_combine(w_clean, pruned_ref)\n",
    "    return ivy.asarray(w_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://download.pytorch.org/models/regnet_y_400mf-c65dace8.pth\"\n",
    "w_clean = load_torch_weights(\n",
    "    url,\n",
    "    model,\n",
    "    raw_keys_to_prune=[\"num_batches_tracked\"],\n",
    "    custom_mapping=_RegNet_Y_400MF_torch_weights_mapping,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing model blocks saperatly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Callable, Any, Tuple, Union, Sequence\n",
    "import ivy\n",
    "import math\n",
    "import warnings\n",
    "import collections\n",
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnyStage(ivy.Sequential):\n",
    "    \"\"\"AnyNet stage (sequence of blocks w/ the same output shape).\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        width_in: int,\n",
    "        width_out: int,\n",
    "        stride: int,\n",
    "        depth: int,\n",
    "        block_constructor: Callable[..., ivy.Module],\n",
    "        norm_layer: Callable[..., ivy.Module],\n",
    "        activation_layer: Callable[..., ivy.Module],\n",
    "        group_width: int,\n",
    "        bottleneck_multiplier: float,\n",
    "        se_ratio: Optional[float] = None,\n",
    "        stage_index: int = 0,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        for i in range(depth):\n",
    "            block = block_constructor(\n",
    "                width_in if i == 0 else width_out,\n",
    "                width_out,\n",
    "                stride if i == 0 else 1,\n",
    "                norm_layer,\n",
    "                activation_layer,\n",
    "                group_width,\n",
    "                bottleneck_multiplier,\n",
    "                se_ratio,\n",
    "            )\n",
    "\n",
    "            self.add_module(f\"block{stage_index}-{i}\", block)\n",
    "\n",
    "\n",
    "def test_AnyStage():\n",
    "    # N x 768 x 5 x 5\n",
    "    random_test_tensor = ivy.random_normal(shape=(1, 5, 5, 768))\n",
    "    display(f\"random_test_tensor shape is: {random_test_tensor.shape}\")\n",
    "\n",
    "    block = AnyStage(\n",
    "        32,\n",
    "        width_out,\n",
    "        stride,\n",
    "        depth,\n",
    "        block_type,\n",
    "        norm_layer,\n",
    "        activation,\n",
    "        group_width,\n",
    "        bottleneck_multiplier,\n",
    "        block_params.se_ratio,\n",
    "        stage_index=i + 1,\n",
    "    )\n",
    "    block(random_test_tensor)\n",
    "    # N x 128 x 5 x 5\n",
    "    display(\"Test Successfull!\")\n",
    "\n",
    "\n",
    "test_AnyStage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing BlockPrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockParams:\n",
    "    def __init__(\n",
    "        self,\n",
    "        depths: List[int],\n",
    "        widths: List[int],\n",
    "        group_widths: List[int],\n",
    "        bottleneck_multipliers: List[float],\n",
    "        strides: List[int],\n",
    "        se_ratio: Optional[float] = None,\n",
    "    ) -> None:\n",
    "        self.depths = depths\n",
    "        self.widths = widths\n",
    "        self.group_widths = group_widths\n",
    "        self.bottleneck_multipliers = bottleneck_multipliers\n",
    "        self.strides = strides\n",
    "        self.se_ratio = se_ratio\n",
    "\n",
    "    @classmethod\n",
    "    def from_init_params(\n",
    "        cls,\n",
    "        depth: int,\n",
    "        w_0: int,\n",
    "        w_a: float,\n",
    "        w_m: float,\n",
    "        group_width: int,\n",
    "        bottleneck_multiplier: float = 1.0,\n",
    "        se_ratio: Optional[float] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> \"BlockParams\":\n",
    "        \"\"\"\n",
    "        Programmatically compute all the per-block settings,\n",
    "        given the RegNet parameters.\n",
    "\n",
    "        The first step is to compute the quantized linear block parameters,\n",
    "        in log space. Key parameters are:\n",
    "        - `w_a` is the width progression slope\n",
    "        - `w_0` is the initial width\n",
    "        - `w_m` is the width stepping in the log space\n",
    "\n",
    "        In other terms\n",
    "        `log(block_width) = log(w_0) + w_m * block_capacity`,\n",
    "        with `bock_capacity` ramping up following the w_0 and w_a params.\n",
    "        This block width is finally quantized to multiples of 8.\n",
    "\n",
    "        The second step is to compute the parameters per stage,\n",
    "        taking into account the skip connection and the final 1x1 convolutions.\n",
    "        We use the fact that the output width is constant within a stage.\n",
    "        \"\"\"\n",
    "\n",
    "        QUANT = 8\n",
    "        STRIDE = 2\n",
    "\n",
    "        if w_a < 0 or w_0 <= 0 or w_m <= 1 or w_0 % 8 != 0:\n",
    "            raise ValueError(\"Invalid RegNet settings\")\n",
    "        # Compute the block widths. Each stage has one unique block width\n",
    "        widths_cont = ivy.arange(depth) * w_a + w_0\n",
    "        block_capacity = ivy.round(ivy.log(widths_cont / w_0) / math.log(w_m))\n",
    "        block_widths = ivy.to_list(\n",
    "            ivy.int32(\n",
    "                ivy.round(ivy.divide(w_0 * ivy.pow(w_m, block_capacity), QUANT)) * QUANT\n",
    "            )\n",
    "        )\n",
    "        num_stages = len(set(block_widths))\n",
    "\n",
    "        # Convert to per stage parameters\n",
    "        split_helper = zip(\n",
    "            block_widths + [0],\n",
    "            [0] + block_widths,\n",
    "            block_widths + [0],\n",
    "            [0] + block_widths,\n",
    "        )\n",
    "        splits = [w != wp or r != rp for w, wp, r, rp in split_helper]\n",
    "\n",
    "        stage_widths = [w for w, t in zip(block_widths, splits[:-1]) if t]\n",
    "        stage_depths = (\n",
    "            ivy.diff(ivy.array([d for d, t in enumerate(splits) if t])).int().tolist()\n",
    "        )\n",
    "\n",
    "        strides = [STRIDE] * num_stages\n",
    "        bottleneck_multipliers = [bottleneck_multiplier] * num_stages\n",
    "        group_widths = [group_width] * num_stages\n",
    "\n",
    "        # Adjust the compatibility of stage widths and group widths\n",
    "        stage_widths, group_widths = cls._adjust_widths_groups_compatibilty(\n",
    "            stage_widths, bottleneck_multipliers, group_widths\n",
    "        )\n",
    "\n",
    "        return cls(\n",
    "            depths=stage_depths,\n",
    "            widths=stage_widths,\n",
    "            group_widths=group_widths,\n",
    "            bottleneck_multipliers=bottleneck_multipliers,\n",
    "            strides=strides,\n",
    "            se_ratio=se_ratio,\n",
    "        )\n",
    "\n",
    "    def _get_expanded_params(self):\n",
    "        return zip(\n",
    "            self.widths,\n",
    "            self.strides,\n",
    "            self.depths,\n",
    "            self.group_widths,\n",
    "            self.bottleneck_multipliers,\n",
    "        )\n",
    "\n",
    "    def _make_divisible(v: float, divisor: int, min_value: Optional[int] = None) -> int:\n",
    "        \"\"\"\n",
    "        This function is taken from the original tf repo.\n",
    "        It ensures that all layers have a channel number that is divisible by 8\n",
    "        It can be seen here:\n",
    "        https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "        \"\"\"\n",
    "        if min_value is None:\n",
    "            min_value = divisor\n",
    "        new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "        # Make sure that round down does not go down by more than 10%.\n",
    "        if new_v < 0.9 * v:\n",
    "            new_v += divisor\n",
    "        return new_v\n",
    "\n",
    "    @staticmethod\n",
    "    def _adjust_widths_groups_compatibilty(\n",
    "        stage_widths: List[int], bottleneck_ratios: List[float], group_widths: List[int]\n",
    "    ) -> Tuple[List[int], List[int]]:\n",
    "        \"\"\"\n",
    "        Adjusts the compatibility of widths and groups,\n",
    "        depending on the bottleneck ratio.\n",
    "        \"\"\"\n",
    "        # Compute all widths for the current settings\n",
    "        widths = [int(w * b) for w, b in zip(stage_widths, bottleneck_ratios)]\n",
    "        group_widths_min = [min(g, w_bot) for g, w_bot in zip(group_widths, widths)]\n",
    "\n",
    "        # Compute the adjusted widths so that stage and group widths fit\n",
    "        ws_bot = [\n",
    "            _make_divisible(w_bot, g) for w_bot, g in zip(widths, group_widths_min)\n",
    "        ]\n",
    "        stage_widths = [int(w_bot / b) for w_bot, b in zip(ws_bot, bottleneck_ratios)]\n",
    "        return stage_widths, group_widths_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'IntDtype' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/models_Ivy_Sark42/ivy_models/regnet/lab.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bominous-bassoon-p7jjw5w7557f944q/workspaces/models_Ivy_Sark42/ivy_models/regnet/lab.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m BlockParams\u001b[39m.\u001b[39;49mfrom_init_params(\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bominous-bassoon-p7jjw5w7557f944q/workspaces/models_Ivy_Sark42/ivy_models/regnet/lab.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     depth\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m, w_0\u001b[39m=\u001b[39;49m\u001b[39m48\u001b[39;49m, w_a\u001b[39m=\u001b[39;49m\u001b[39m27.89\u001b[39;49m, w_m\u001b[39m=\u001b[39;49m\u001b[39m2.09\u001b[39;49m, group_width\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m, se_ratio\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bominous-bassoon-p7jjw5w7557f944q/workspaces/models_Ivy_Sark42/ivy_models/regnet/lab.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m )\n",
      "\u001b[1;32m/workspaces/models_Ivy_Sark42/ivy_models/regnet/lab.ipynb Cell 14\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bominous-bassoon-p7jjw5w7557f944q/workspaces/models_Ivy_Sark42/ivy_models/regnet/lab.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m widths_cont \u001b[39m=\u001b[39m ivy\u001b[39m.\u001b[39marange(depth) \u001b[39m*\u001b[39m w_a \u001b[39m+\u001b[39m w_0\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bominous-bassoon-p7jjw5w7557f944q/workspaces/models_Ivy_Sark42/ivy_models/regnet/lab.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m block_capacity \u001b[39m=\u001b[39m ivy\u001b[39m.\u001b[39mround(ivy\u001b[39m.\u001b[39mlog(widths_cont \u001b[39m/\u001b[39m w_0) \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39mlog(w_m))\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bominous-bassoon-p7jjw5w7557f944q/workspaces/models_Ivy_Sark42/ivy_models/regnet/lab.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m block_widths \u001b[39m=\u001b[39m ivy\u001b[39m.\u001b[39mto_list(\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bominous-bassoon-p7jjw5w7557f944q/workspaces/models_Ivy_Sark42/ivy_models/regnet/lab.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m     ivy\u001b[39m.\u001b[39;49mint32(\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bominous-bassoon-p7jjw5w7557f944q/workspaces/models_Ivy_Sark42/ivy_models/regnet/lab.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m         ivy\u001b[39m.\u001b[39;49mround(ivy\u001b[39m.\u001b[39;49mdivide(w_0 \u001b[39m*\u001b[39;49m ivy\u001b[39m.\u001b[39;49mpow(w_m, block_capacity), QUANT)) \u001b[39m*\u001b[39;49m QUANT\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bominous-bassoon-p7jjw5w7557f944q/workspaces/models_Ivy_Sark42/ivy_models/regnet/lab.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bominous-bassoon-p7jjw5w7557f944q/workspaces/models_Ivy_Sark42/ivy_models/regnet/lab.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bominous-bassoon-p7jjw5w7557f944q/workspaces/models_Ivy_Sark42/ivy_models/regnet/lab.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m num_stages \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(block_widths))\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bominous-bassoon-p7jjw5w7557f944q/workspaces/models_Ivy_Sark42/ivy_models/regnet/lab.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39m# Convert to per stage parameters\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'IntDtype' object is not callable"
     ]
    }
   ],
   "source": [
    "BlockParams.from_init_params(\n",
    "    depth=16, w_0=48, w_a=27.89, w_m=2.09, group_width=8, se_ratio=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
